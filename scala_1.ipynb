{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "println(\"ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -3) vérifier que le spark context est disponible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.SparkContext@7ba72055"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -2) imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -1) refaire un spark context personnalisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.SparkConf@1ddd9406"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val appName = \"rennes\"\n",
    "val master  = \"local[3]\"\n",
    "val conf    = new SparkConf()\n",
    "conf.setAppName(appName)\n",
    "conf.setMaster(master)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "val sc = new SparkContext(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "local[3]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Créer une première rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) lecture d'un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val cyclistes = sc.textFile(\"./logs_backup/cycliste_cyclistes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclistes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(cycliste_azetu,6,31,femme,8.11111516393,21.9593538999,100, cycliste_aztv4,2,19,femme,10.5299319612,22.1102025653,8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclistes.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val velos = sc.textFile(\"./logs_backup/velos_etats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(velo_azem4,1485439420.58,azf38,0.95,97.3984151307)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velos.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2) filtrer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val velos2 = velos.filter(!_.isEmpty() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remarque : en scala il faut faire précéder les chaines par la lettre [s] pour pouvoir afficher la valeur de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fichier = 128668, lignes non vides =  64334\n"
     ]
    }
   ],
   "source": [
    "val nb_lignes = velos.count()\n",
    "println(s\"fichier = ${velos.count()}, lignes non vides =  ${velos2.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) convertir un fichier en table sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0) importer les librairies sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.Row;\n",
    "import org.apache.spark.sql.types.{StructType, StructField, StringType};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1) créer un sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(velos)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.tableNames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2) définir le schéma de la table vélo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var champs = List(  StructField(\"nom\"          , StringType, true),\n",
    "                    StructField(\"time\"         , StringType, true),\n",
    "                    StructField(\"station\"      , StringType, true),\n",
    "                    StructField(\"performance\"  , StringType, true),\n",
    "                    StructField(\"nb_km_trajet\" , StringType, true))\n",
    "var schema = StructType(champs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Transformer les lignes en tableau d'objet spécifiques : les 'Row'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val rowRDD = velos2.map(_.split(\",\")).map(champs => Row(champs(0), champs(1), champs(2),champs(3),champs(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4) créer une DataFrame via le sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val veloDF = sqlContext.createDataFrame(rowRDD, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5) Enregistrer la DataFrame en tant que table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val table_velos = \"velos\"\n",
    "veloDF.registerTempTable(table_velos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6) Requêter la table avec du SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### requete 01 : compte le nb de lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   64334|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val requete = s\"Select count(*) from ${table_velos}\"\n",
    "sqlContext.sql(requete).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### requete 02 : nb de nom distincts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT nom)|\n",
      "+-------------------+\n",
      "|                760|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val requete = s\"Select count( distinct nom) from ${table_velos}\"\n",
    "sqlContext.sql(requete).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### requete 03 : performance moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|avg(CAST(performance AS DOUBLE))|\n",
      "+--------------------------------+\n",
      "|              0.7615443430900648|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// performance moyenne : \n",
    "val requete = s\"Select mean( performance) from ${table_velos}\"\n",
    "sqlContext.sql(requete).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### requete 04 : multi champs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 140:====================================================>(198 + 2) / 200]+----------+-----------------+------------------+-----------------+------------------+----------+\n",
      "|       nom|min(nb_km_trajet)|           moyenne|max(nb_km_trajet)|             somme|nb_station|\n",
      "+----------+-----------------+------------------+-----------------+------------------+----------+\n",
      "|velo_aeyi6|    106.124133158|  250.712765889171|    98.2821292635|25321.989354806272|        46|\n",
      "|velo_azow8|    1000.72528089| 640.1191001270846|    994.915022987|129304.05822567109|        60|\n",
      "|velo_aeqx7|    49.6741505596|     49.6741505596|    49.6741505596|     49.6741505596|         1|\n",
      "|velo_aeufh|     102.45730718|  364.425467797552|    95.8711122327| 36806.97224755275|        48|\n",
      "|velo_arod5|    101.702990964|352.68417590080105|    90.3094170541| 35621.10176598091|        48|\n",
      "|velo_artu7|    100.583333498|374.04519581147616|    96.9156508692|37778.564776959094|        60|\n",
      "|velo_azdf6|    109.735413268|     109.735413268|    109.735413268|     109.735413268|         1|\n",
      "|velo_aeqf9|    1007.13554138|   931.52806195232|    999.600565032|282253.00277155294|        64|\n",
      "|velo_aerys|    111.742940242|381.43054944244847|    97.9444200301|38524.485493687294|        49|\n",
      "|velo_aeyiq|    10.9633640885|323.05327119470417|    91.4809932604| 32628.38039066512|        53|\n",
      "|velo_aelv1|     1.9486169998|388.58128155786426|    98.5165466323| 39246.70943734429|        61|\n",
      "|velo_azqm1|    10.7852923649| 835.7150737146325|    997.860350763|253221.66733553362|        75|\n",
      "|velo_aztx1|    116.152178975| 319.4781955545808|    99.7633115706|32267.297751012662|        50|\n",
      "|velo_aei57|    1003.94407292| 781.0789256868909|     990.09328608|157777.94298875195|        68|\n",
      "|velo_arpjv|    104.164487993|236.38422851716138|    99.4995273835|  23874.8070802333|        44|\n",
      "|velo_azkw8|   -0.97367022698| 273.7167038795087|    97.9085622758| 27645.38709183038|        38|\n",
      "|velo_ars89|    59.8932657472|     59.8932657472|    59.8932657472|     59.8932657472|         1|\n",
      "|velo_aeqxn|    101.616977267|248.59694096306933|    92.0145925841|25108.291037270003|        48|\n",
      "|velo_artm0|     84.161263584|      84.161263584|     84.161263584|      84.161263584|         1|\n",
      "|velo_artsd|     99.508326874|      99.508326874|     99.508326874|      99.508326874|         1|\n",
      "+----------+-----------------+------------------+-----------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val requete = s\"\"\"\n",
    "Select nom                                       , \n",
    "       min   ( nb_km_trajet     )                , \n",
    "       mean  ( nb_km_trajet     ) as moyenne     ,  \n",
    "       max   ( nb_km_trajet     )                ,\n",
    "       sum   ( nb_km_trajet     ) as somme       ,\n",
    "       count ( distinct station ) as nb_station\n",
    "       \n",
    "from ${table_velos}\n",
    "group by nom\n",
    "\"\"\"\n",
    "sqlContext.sql(requete).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//import org.joda.time.{DateTimeZone}\n",
    "//import org.joda.time.format.DateTimeFormat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### requete 05 : conversion de timestamp en date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+\n",
      "|       nom|    premiere_sortie|    derniere_sortie|\n",
      "+----------+-------------------+-------------------+\n",
      "|velo_aeyi6|2017-01-26 14:08:41|2017-01-26 14:28:02|\n",
      "|velo_azow8|2017-01-26 14:11:32|2017-01-26 14:38:02|\n",
      "|velo_aeqx7|2017-01-26 14:03:22|2017-01-26 14:03:22|\n",
      "|velo_aeufh|2017-01-26 14:06:59|2017-01-26 14:25:08|\n",
      "|velo_arod5|2017-01-26 14:06:43|2017-01-26 14:22:34|\n",
      "|velo_artu7|2017-01-26 14:06:43|2017-01-26 14:17:00|\n",
      "|velo_azdf6|2017-01-26 14:03:43|2017-01-26 14:03:43|\n",
      "|velo_aeqf9|2017-01-26 14:06:43|2017-01-26 14:29:22|\n",
      "|velo_aerys|2017-01-26 14:11:29|2017-01-26 14:21:55|\n",
      "|velo_aeyiq|2017-01-26 14:06:59|2017-01-26 14:14:36|\n",
      "|velo_aelv1|2017-01-26 14:06:48|2017-01-26 14:20:03|\n",
      "|velo_azqm1|2017-01-26 14:06:48|2017-01-26 14:25:03|\n",
      "|velo_aztx1|2017-01-26 14:06:58|2017-01-26 14:10:09|\n",
      "|velo_aei57|2017-01-26 14:07:53|2017-01-26 14:20:23|\n",
      "|velo_arpjv|2017-01-26 14:06:44|2017-01-26 14:18:25|\n",
      "|velo_azkw8|2017-01-26 14:13:48|2017-01-26 14:26:40|\n",
      "|velo_ars89|2017-01-26 14:03:36|2017-01-26 14:03:36|\n",
      "|velo_aeqxn|2017-01-26 14:06:43|2017-01-26 14:14:49|\n",
      "|velo_artm0|2017-01-26 14:03:41|2017-01-26 14:03:41|\n",
      "|velo_artsd|2017-01-26 14:03:37|2017-01-26 14:03:37|\n",
      "+----------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val requete = s\"\"\"\n",
    "Select  nom,\n",
    "        min(from_unixtime(time,'YYYY-MM-dd HH:mm:ss')) as premiere_sortie, \n",
    "        max(from_unixtime(time,'YYYY-MM-dd HH:mm:ss')) as derniere_sortie                \n",
    "        from ${table_velos}\n",
    "        group by nom\n",
    "\"\"\"\n",
    "sqlContext.sql(requete).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### requete 06 : imbrication de requêtes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|       nom|   duree|\n",
      "+----------+--------+\n",
      "|velo_aeyi6|00:19:20|\n",
      "|velo_azow8|00:26:29|\n",
      "|velo_aeqx7|00:00:00|\n",
      "|velo_aeufh|00:18:09|\n",
      "|velo_arod5|00:15:51|\n",
      "|velo_artu7|00:10:16|\n",
      "|velo_azdf6|00:00:00|\n",
      "|velo_aeqf9|00:22:39|\n",
      "|velo_aerys|00:10:26|\n",
      "|velo_aeyiq|00:07:37|\n",
      "|velo_aelv1|00:13:14|\n",
      "|velo_azqm1|00:18:14|\n",
      "|velo_aztx1|00:03:10|\n",
      "|velo_aei57|00:12:30|\n",
      "|velo_arpjv|00:11:40|\n",
      "|velo_azkw8|00:12:51|\n",
      "|velo_ars89|00:00:00|\n",
      "|velo_aeqxn|00:08:05|\n",
      "|velo_artm0|00:00:00|\n",
      "|velo_artsd|00:00:00|\n",
      "+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val requete = s\"\"\"\n",
    "Select  nom, \n",
    "        from_unixtime(derniere_sortie - premiere_sortie, 'HH:mm:ss') as duree\n",
    "from\n",
    "(       Select  nom,\n",
    "                min(time) as premiere_sortie, \n",
    "                max(time) as derniere_sortie                \n",
    "        from ${table_velos}\n",
    "        group by nom\n",
    "        )\n",
    "\"\"\"\n",
    "sqlContext.sql(requete).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3) reading csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var champs         = List(  StructField(\"nom\"    , StringType, true) ,\n",
    "                            StructField(\"heure\"  , StringType, true) ,\n",
    "                            StructField(\"velo\"   , StringType, true) ,\n",
    "                            StructField(\"action\" , StringType, true) )\n",
    "var schema         = StructType(champs)\n",
    "val DataSet_prise  = sqlContext.read.schema(schema).csv(\"./logs_backup/cycliste_prises.csv\")\n",
    "val table_prises   = \"prises\"\n",
    "DataSet_prise.registerTempTable(table_prises)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var champs = List(  StructField(\"cyclise\"  , StringType, true),\n",
    "                    StructField(\"heure\"    , StringType, true),\n",
    "                    StructField(\"rendu\"    , StringType, true),\n",
    "                    StructField(\"duree\"    , StringType, true),\n",
    "                    StructField(\"velo\"     , StringType, true))\n",
    "var r_schema = StructType(champs)\n",
    "val DataSet_rendu = sqlContext.read.schema(r_schema).csv(\"./logs_backup/cycliste_rendu.csv\")\n",
    "val table_rendu = \"rendus\"\n",
    "DataSet_rendu.registerTempTable(table_rendu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+-------------+-------------+-------------+\n",
      "|           nom|        heure|        heure|        rendu|        duree|\n",
      "+--------------+-------------+-------------+-------------+-------------+\n",
      "|cycliste_aze10|1485439602.26|1485440311.39| 1485440312.6|11.1029811867|\n",
      "|cycliste_aze10|1485439630.58|1485440148.91|1485440149.29|9.76041518677|\n",
      "|cycliste_aze10|1485439745.23|1485439681.31|1485439681.89|12.8273055141|\n",
      "|cycliste_aze10|1485439757.55|1485439623.96|1485439624.41|7.85567722207|\n",
      "|cycliste_aze10|1485439783.18|1485439938.97| 1485439939.1|3.96409418747|\n",
      "|cycliste_aze10|1485439783.18|1485440619.75|1485440619.99|4.71465658798|\n",
      "|cycliste_aze10| 1485439795.9|1485439693.79|1485439693.79|            0|\n",
      "|cycliste_aze10|1485439808.25|1485439902.99|1485439903.27|8.24423764551|\n",
      "|cycliste_aze10|1485439834.83|1485439727.11|1485439727.79|6.21738885458|\n",
      "|cycliste_aze10|1485439847.64|1485439968.62|1485439968.82| 6.0272283344|\n",
      "|cycliste_aze10|1485439860.77|1485439653.45|1485439653.69|4.28558477138|\n",
      "|cycliste_aze10|1485439860.77| 1485439986.8| 1485439987.2| 4.3665956822|\n",
      "|cycliste_aze10|1485439898.44|1485439894.56|1485439894.75|3.23432167832|\n",
      "|cycliste_aze10|1485439924.92|1485440565.41|1485440565.69|7.92829602863|\n",
      "|cycliste_aze10|1485440018.77|1485439994.29|1485439995.02|13.0728497595|\n",
      "|cycliste_aze10|1485440018.77|1485440157.76|1485440158.48|11.1247056683|\n",
      "|cycliste_aze10|1485440018.77|1485440170.84|1485440171.07|4.94710766085|\n",
      "|cycliste_aze10| 1485440096.2|1485440502.74|1485440502.93|5.01502478567|\n",
      "|cycliste_aze10|1485440109.83|1485439818.28|1485439819.24|12.5337319054|\n",
      "|cycliste_aze10|1485440109.83|1485440200.29|1485440200.55|3.54996456376|\n",
      "+--------------+-------------+-------------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val requete = s\"\"\"  SELECT distinct  p.nom     , \n",
    "                                     p.heure   , \n",
    "                                     r.heure   ,\n",
    "                                     r.rendu   ,\n",
    "                                     r.duree   \n",
    "                    FROM        prises AS p \n",
    "                    INNER JOIN  rendus AS r \n",
    "                    ON          p.velo = r.velo\n",
    "\"\"\"\n",
    "sqlContext.sql(requete).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.sql.AnalysisException\n",
       "Message: cannot resolve '`p.heure`' given input columns: [action, nom, nom, heure , heure , velo, velo, action]; line 2 pos 41;\n",
       "'Distinct\n",
       "+- 'Project [nom#1869, velo#1871, action#1872, 'p.heure, action#1881, 'r.heure]\n",
       "   +- Join Inner, (velo#1871 = velo#1880)\n",
       "      :- SubqueryAlias p\n",
       "      :  +- SubqueryAlias prises\n",
       "      :     +- Relation[nom#1869,heure #1870,velo#1871,action#1872] csv\n",
       "      +- SubqueryAlias r\n",
       "         +- SubqueryAlias rendus\n",
       "            +- Relation[nom#1878,heure #1879,velo#1880,action#1881] csv\n",
       "\n",
       "StackTrace: 'Distinct\n",
       "+- 'Project [nom#1869, velo#1871, action#1872, 'p.heure, action#1881, 'r.heure]\n",
       "   +- Join Inner, (velo#1871 = velo#1880)\n",
       "      :- SubqueryAlias p\n",
       "      :  +- SubqueryAlias prises\n",
       "      :     +- Relation[nom#1869,heure #1870,velo#1871,action#1872] csv\n",
       "      +- SubqueryAlias r\n",
       "         +- SubqueryAlias rendus\n",
       "            +- Relation[nom#1878,heure #1879,velo#1880,action#1881] csv\n",
       "\n",
       "  at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n",
       "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:77)\n",
       "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:74)\n",
       "  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:308)\n",
       "  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:308)\n",
       "  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n",
       "  at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:307)\n",
       "  at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionUp$1(QueryPlan.scala:269)\n",
       "  at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$2(QueryPlan.scala:279)\n",
       "  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$2$1.apply(QueryPlan.scala:283)\n",
       "  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n",
       "  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n",
       "  at scala.collection.immutable.List.foreach(List.scala:381)\n",
       "  at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n",
       "  at scala.collection.immutable.List.map(List.scala:285)\n",
       "  at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$2(QueryPlan.scala:283)\n",
       "  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$8.apply(QueryPlan.scala:288)\n",
       "  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n",
       "  at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:288)\n",
       "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:74)\n",
       "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:67)\n",
       "  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n",
       "  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:125)\n",
       "  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:125)\n",
       "  at scala.collection.immutable.List.foreach(List.scala:381)\n",
       "  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)\n",
       "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:67)\n",
       "  at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:58)\n",
       "  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:49)\n",
       "  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:64)\n",
       "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:582)\n",
       "  at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:682)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val requete = s\"\"\"\n",
    "Select distinct p.nom, p.velo, p.action, p.heure, r.action, r.heure\n",
    "from    prises as p\n",
    "Join    rendus as r\n",
    "ON p.velo == r.velo\n",
    "\"\"\"\n",
    "\n",
    "sqlContext.sql(requete).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class org.apache.spark.sql.Dataset"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_prise.getClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:82: error: Unable to find encoder for type stored in a Dataset.  Primitive types (Int, String, etc) and Product types (case classes) are supported by importing spark.implicits._  Support for serializing other types will be added in future releases.\n",
       "       DF_prise.map(champs => Row(champs(0), champs(1), champs(2),champs(3)))\n",
       "                   ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_prise.map(champs => Row(champs(0), champs(1), champs(2),champs(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
